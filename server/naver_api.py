#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Naver API Integration for Blog and Cafe Search
"""

import requests
import urllib.parse
import sys

NAVER_CLIENT_ID = "YINpbvMCsck1Vr0PwwJd"
NAVER_CLIENT_SECRET = "gdi7lnyV1Z"

def search_naver(keyword, search_type="blog", display=10):
    """
    Search Naver Blog or Cafe articles
    
    Args:
        keyword: Search keyword
        search_type: 'blog' or 'cafe'
        display: Number of results to return (max 100)
        
    Returns:
        List of search results
    """
    base_url = {
        "blog": "https://openapi.naver.com/v1/search/blog",
        "cafe": "https://openapi.naver.com/v1/search/cafearticle"
    }.get(search_type)

    if not base_url:
        raise ValueError("search_typeì€ 'blog' ë˜ëŠ” 'cafe' ì´ì–´ì•¼ í•©ë‹ˆë‹¤")

    # ğŸ” í‚¤ì›Œë“œë¥¼ ë”°ì˜´í‘œë¡œ ê°ì‹¸ ì •í™• ê²€ìƒ‰ ìœ ë„
    query = urllib.parse.quote(f'"{keyword}"')  
    url = f"{base_url}?query={query}&display={display}"

    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET
    }

    try:
        res = requests.get(url, headers=headers, timeout=10)
        
        if res.status_code == 200:
            return res.json().get("items", [])
        else:
            print(f"ë„¤ì´ë²„ API ì˜¤ë¥˜: {res.status_code} - {res.text}", file=sys.stderr)
            return []
    except requests.exceptions.RequestException as e:
        print(f"ë„¤ì´ë²„ API ìš”ì²­ ì‹¤íŒ¨: {str(e)}", file=sys.stderr)
        return []

def extract_text_from_html(html_content):
    """
    Extract plain text from HTML content
    
    Args:
        html_content: HTML string
        
    Returns:
        Plain text string
    """
    import re
    
    # Remove HTML tags
    clean_text = re.sub(r'<[^>]+>', '', html_content)
    
    # Decode HTML entities
    clean_text = clean_text.replace('&lt;', '<').replace('&gt;', '>').replace('&amp;', '&')
    clean_text = clean_text.replace('&quot;', '"').replace('&#39;', "'")
    
    # Remove extra whitespace
    clean_text = re.sub(r'\s+', ' ', clean_text).strip()
    
    return clean_text

def strip_html(html_content):
    """
    Strip HTML tags from content
    
    Args:
        html_content: HTML string
        
    Returns:
        Plain text string
    """
    import re
    
    # Remove HTML tags
    clean_text = re.sub(r'<[^>]+>', '', html_content)
    
    # Decode HTML entities
    clean_text = clean_text.replace('&lt;', '<').replace('&gt;', '>').replace('&amp;', '&')
    clean_text = clean_text.replace('&quot;', '"').replace('&#39;', "'")
    
    # Remove extra whitespace
    clean_text = re.sub(r'\s+', ' ', clean_text).strip()
    
    return clean_text

def is_likely_user_review(item, service_keywords):
    """
    Check if the search result item is likely a genuine user review
    
    Args:
        item: Search result item from Naver API
        service_keywords: List of service-related keywords
        
    Returns:
        Boolean indicating if this is likely a user review
    """
    # HTML ì œê±°
    title = strip_html(item.get("title", "")).lower()
    desc = strip_html(item.get("description", "")).lower()
    text = title + " " + desc

    # 1. í‚¤ì›Œë“œ í¬í•¨ ë¬¸ì¥
    review_signals = ["í›„ê¸°", "ë¦¬ë·°", "ì‚¬ìš©ê¸°", "ì¨ë´¤ì–´ìš”", "ì¶”ì²œ", "ë‹¨ì ", "ì¥ì ", "ë¶ˆí¸", "ì¢‹ì•˜ë˜ ì "]
    if not any(kw in text for kw in review_signals):
        return False

    # 2. ê¸°ì‚¬/ë¸Œëœë“œ ì¤‘ì‹¬ í‚¤ì›Œë“œ ë°˜ë³µ â†’ ì œì™¸
    if text.count("press") > 0 or text.count("ë³´ë„ìë£Œ") > 0:
        return False

    # 3. ê¸¸ì´ ì œí•œ (ë„ˆë¬´ ì§§ìœ¼ë©´ ì œì™¸)
    if len(text) < 30:
        return False

    # 4. ì„œë¹„ìŠ¤ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê³ ê° ì–¸ì–´ë¡œ ì“°ì˜€ëŠ”ì§€ í™•ì¸ (ë³´ì™„)
    if not any(sk.lower() in text for sk in service_keywords):
        return False

    return True