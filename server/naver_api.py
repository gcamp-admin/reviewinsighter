#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Naver API Integration for Blog and Cafe Search
"""

import requests
import urllib.parse
import sys
import re

NAVER_CLIENT_ID = "YINpbvMCsck1Vr0PwwJd"
NAVER_CLIENT_SECRET = "gdi7lnyV1Z"

def extract_user_id_from_url(bloggerlink, link, search_type):
    """
    Extract user ID from Naver Blog or Cafe URL
    
    Args:
        bloggerlink: Blogger link (for blog)
        link: Direct link to the content
        search_type: 'blog' or 'cafe'
        
    Returns:
        Extracted user ID or default value
    """
    try:
        if search_type == "blog":
            # For blog, try to extract from bloggerlink first
            if bloggerlink:
                # Pattern: https://blog.naver.com/USERNAME
                match = re.search(r'blog\.naver\.com/([^/?]+)', bloggerlink)
                if match:
                    return match.group(1)
            
            # If bloggerlink fails, try from link
            if link:
                # Pattern: https://blog.naver.com/USERNAME/POST_ID
                match = re.search(r'blog\.naver\.com/([^/?]+)', link)
                if match:
                    return match.group(1)
                    
        elif search_type == "cafe":
            # For cafe, extract from link
            if link:
                # Pattern: https://cafe.naver.com/CAFE_NAME/ARTICLE_ID
                match = re.search(r'cafe\.naver\.com/([^/?]+)', link)
                if match:
                    return f"ì¹´í˜_{match.group(1)}"
                    
        return None
        
    except Exception as e:
        print(f"Error extracting user ID: {str(e)}", file=sys.stderr)
        return None

def search_naver(keyword, search_type="blog", display=10):
    """
    Search Naver Blog or Cafe articles
    
    Args:
        keyword: Search keyword
        search_type: 'blog' or 'cafe'
        display: Number of results to return (max 100)
        
    Returns:
        List of search results
    """
    base_url = {
        "blog": "https://openapi.naver.com/v1/search/blog",
        "cafe": "https://openapi.naver.com/v1/search/cafearticle"
    }.get(search_type)

    if not base_url:
        raise ValueError("search_typeì€ 'blog' ë˜ëŠ” 'cafe' ì´ì–´ì•¼ í•©ë‹ˆë‹¤")

    # ğŸ” í‚¤ì›Œë“œë¥¼ ë”°ì˜´í‘œë¡œ ê°ì‹¸ ì •í™• ê²€ìƒ‰ ìœ ë„
    query = urllib.parse.quote(f'"{keyword}"')  
    url = f"{base_url}?query={query}&display={display}"

    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET
    }

    try:
        res = requests.get(url, headers=headers, timeout=10)
        
        if res.status_code == 200:
            items = res.json().get("items", [])
            # Extract user IDs from URLs
            for item in items:
                user_id = extract_user_id_from_url(item.get('bloggerlink', ''), item.get('link', ''), search_type)
                item['extracted_user_id'] = user_id
            return items
        else:
            print(f"ë„¤ì´ë²„ API ì˜¤ë¥˜: {res.status_code} - {res.text}", file=sys.stderr)
            return []
    except requests.exceptions.RequestException as e:
        print(f"ë„¤ì´ë²„ API ìš”ì²­ ì‹¤íŒ¨: {str(e)}", file=sys.stderr)
        return []

def extract_text_from_html(html_content):
    """
    Extract plain text from HTML content
    
    Args:
        html_content: HTML string
        
    Returns:
        Plain text string
    """
    import re
    
    # Remove HTML tags
    clean_text = re.sub(r'<[^>]+>', '', html_content)
    
    # Decode HTML entities
    clean_text = clean_text.replace('&lt;', '<').replace('&gt;', '>').replace('&amp;', '&')
    clean_text = clean_text.replace('&quot;', '"').replace('&#39;', "'")
    
    # Remove extra whitespace
    clean_text = re.sub(r'\s+', ' ', clean_text).strip()
    
    return clean_text

def strip_html(html_content):
    """
    Strip HTML tags from content
    
    Args:
        html_content: HTML string
        
    Returns:
        Plain text string
    """
    import re
    
    # Remove HTML tags
    clean_text = re.sub(r'<[^>]+>', '', html_content)
    
    # Decode HTML entities
    clean_text = clean_text.replace('&lt;', '<').replace('&gt;', '>').replace('&amp;', '&')
    clean_text = clean_text.replace('&quot;', '"').replace('&#39;', "'")
    
    # Remove extra whitespace
    clean_text = re.sub(r'\s+', ' ', clean_text).strip()
    
    return clean_text

def is_likely_user_review(item, service_keywords):
    """
    Check if the search result item is likely a genuine user review
    
    Args:
        item: Search result item from Naver API
        service_keywords: List of service-related keywords
        
    Returns:
        Boolean indicating if this is likely a user review
    """
    # HTML ì œê±°
    title = strip_html(item.get("title", "")).lower()
    desc = strip_html(item.get("description", "")).lower()
    text = title + " " + desc

    # 1. í‚¤ì›Œë“œ í¬í•¨ ë¬¸ì¥
    review_signals = ["í›„ê¸°", "ë¦¬ë·°", "ì‚¬ìš©ê¸°", "ì¨ë´¤ì–´ìš”", "ì¶”ì²œ", "ë‹¨ì ", "ì¥ì ", "ë¶ˆí¸", "ì¢‹ì•˜ë˜ ì "]
    if not any(kw in text for kw in review_signals):
        return False

    # 2. ê¸°ì‚¬/ë¸Œëœë“œ ì¤‘ì‹¬ í‚¤ì›Œë“œ ë°˜ë³µ â†’ ì œì™¸
    if text.count("press") > 0 or text.count("ë³´ë„ìë£Œ") > 0:
        return False

    # 3. ê¸¸ì´ ì œí•œ (ë„ˆë¬´ ì§§ìœ¼ë©´ ì œì™¸)
    if len(text) < 30:
        return False

    # 4. ì„œë¹„ìŠ¤ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê³ ê° ì–¸ì–´ë¡œ ì“°ì˜€ëŠ”ì§€ í™•ì¸ (ë³´ì™„)
    if not any(sk.lower() in text for sk in service_keywords):
        return False

    return True