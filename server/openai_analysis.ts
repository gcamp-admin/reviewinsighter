import OpenAI from "openai";

// the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// Cache for GPT sentiment analysis results to avoid duplicate API calls
const sentimentCache = new Map<string, 'ê¸ì •' | 'ë¶€ì •' | 'ì¤‘ë¦½'>();

// Batch processing for multiple reviews to reduce API calls
// GPT-based HEART framework analysis
export async function analyzeHeartFrameworkWithGPT(reviews: any[]): Promise<any[]> {
  if (!reviews || reviews.length === 0) {
    return [];
  }

  try {
    // Prepare review texts for analysis
    const reviewTexts = reviews.map(review => ({
      content: review.content,
      rating: review.rating,
      source: review.source
    }));

    // Create prompt for detailed UX-focused HEART framework analysis
    const prompt = `
ë‹¤ìŒ ë¦¬ë·°ë“¤ì„ HEART í”„ë ˆì„ì›Œí¬ì— ë”°ë¼ ë¶„ì„í•˜ì—¬ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ UX ê°œì„  ì œì•ˆì„ ìƒì„±í•´ì£¼ì„¸ìš”.

HEART í”„ë ˆì„ì›Œí¬ (UX ê´€ì ):
- Happiness: ì‚¬ìš©ì ë§Œì¡±ë„, ê°ì •ì  ë°˜ì‘, ì‚¬ìš© ì¦ê±°ì›€
- Engagement: ì‚¬ìš©ì ì°¸ì—¬ íŒ¨í„´, ê¸°ëŠ¥ ì‚¬ìš© ë¹ˆë„, ìƒí˜¸ì‘ìš© í’ˆì§ˆ
- Adoption: ìƒˆë¡œìš´ ê¸°ëŠ¥ ë°œê²¬ì„±, í•™ìŠµ ìš©ì´ì„±, ì²« ì‚¬ìš© ê²½í—˜
- Retention: ì¬ì‚¬ìš© ë™ê¸°, ì‚¬ìš©ì ì´íƒˆ ë°©ì§€, ì§€ì†ì  ê°€ì¹˜ ì œê³µ
- Task Success: ì‘ì—… ì™„ë£Œìœ¨, ì˜¤ë¥˜ ë°©ì§€, ì‚¬ìš©ì ëª©í‘œ ë‹¬ì„±

ë¦¬ë·° ë°ì´í„°:
${reviewTexts.slice(0, 10).map((review, index) => `${index + 1}. [${review.source}] í‰ì : ${review.rating}/5
ë‚´ìš©: ${review.content.substring(0, 150)}`).join('\n\n')}

ë¶„ì„ ê²°ê³¼ë¥¼ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”:
{
  "insights": [
    {
      "category": "happiness|engagement|adoption|retention|task_success",
      "title": "ğŸ”´ Critical | HEART: [category] | [ë¬¸ì œìœ í˜•] ([ê±´ìˆ˜]ê±´)",
      "problem_summary": "ì‹¤ì œ ì‚¬ìš©ì í‘œí˜„ì„ ì¸ìš©í•˜ë©° êµ¬ì²´ì ì¸ UX ë¬¸ì œì  ì„¤ëª…. ì‚¬ìš©ìê°€ ì–´ë–¤ ìƒí™©ì—ì„œ ì–´ë–¤ ë¬¸ì œë¥¼ ê²ªì—ˆëŠ”ì§€ ëª…í™•íˆ ê¸°ìˆ ",
      "ux_suggestions": "êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ UX ê°œì„  ì œì•ˆ (3-5ê°œ í•­ëª©)",
      "priority": "critical|major|minor",
      "mention_count": ê±´ìˆ˜,
      "trend": "stable"
    }
  ]
}

UX ê°œì„  ì œì•ˆ ì‘ì„± ê°€ì´ë“œë¼ì¸:
1. ë¬¸ì œ ìƒí™© íŒŒì•…: ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ êµ¬ì²´ì ì¸ ìƒí™©ê³¼ ë¬¸ì œì ì„ ì •í™•íˆ íŒŒì•…
2. ì‚¬ìš©ì í–‰ë™ ë¶„ì„: ì‚¬ìš©ìì˜ í–‰ë™ íŒ¨í„´ê³¼ ê¸°ëŒ€ì¹˜ë¥¼ ê³ ë ¤í•œ ê°œì„  ë°©í–¥ ì„¤ì •
3. êµ¬ì²´ì  í•´ê²° ë°©ì•ˆ: ì¼ë°˜ì ì¸ ì œì•ˆì´ ì•„ë‹Œ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ UX ì†”ë£¨ì…˜ ì œì‹œ

ì˜ˆì‹œ ë¶„ì„:
- ë¦¬ë·°: "ì „í™”ì™”ì„ ë•Œ ì§„ë™ì´ êº¼ì§€ì§€ ì•Šì•„ ë‹¹í™©ìŠ¤ëŸ¬ì› ìŠµë‹ˆë‹¤"
- ë¬¸ì œ ìš”ì•½: ì‚¬ìš©ìê°€ "ì „í™”ì™”ì„ ë•Œ ì§„ë™ì´ êº¼ì§€ì§€ ì•Šì•„ ë‹¹í™©ìŠ¤ëŸ¬ì› ë‹¤"ê³  í‘œí˜„í•˜ë©°, í†µí™” ì¤‘ ì§„ë™ ì œì–´ì— ëŒ€í•œ ë¶ˆí¸í•¨ì„ í˜¸ì†Œ
- UX ê°œì„  ì œì•ˆ:
  â€¢ ì„¤ì • ë©”ë‰´ì— 'í†µí™” ì¤‘ ì§„ë™ ìë™ ë„ê¸°' í† ê¸€ ì˜µì…˜ ì¶”ê°€
  â€¢ í†µí™” í™”ë©´ì— ì§„ë™ on/off ë¹ ë¥¸ ë²„íŠ¼ ë°°ì¹˜
  â€¢ ì²« í†µí™” ì‹œ ì§„ë™ ì„¤ì • ì•ˆë‚´ íŒì—… í‘œì‹œ
  â€¢ í†µí™” ì¤‘ ì§„ë™ ìƒíƒœë¥¼ ì‹œê°ì ìœ¼ë¡œ í‘œì‹œí•˜ëŠ” ì•„ì´ì½˜ ì¶”ê°€

ì˜ˆì‹œ ë¶„ì„ 2:
- ë¦¬ë·°: "ì „í™” ì™€ì„œ ë°›ìœ¼ë©´ ëŠì–´ì§ ì–´ì„¤í”„ê²Œ ë§Œë“¤êº¼ë©´ ì¶œì‹œë¥¼ í•˜ì§€ ë§ì§€"
- ë¬¸ì œ ìš”ì•½: ì‚¬ìš©ìê°€ "ì „í™” ì™€ì„œ ë°›ìœ¼ë©´ ëŠì–´ì§"ì´ë¼ê³  í‘œí˜„í•˜ë©°, í†µí™” ì—°ê²° ì•ˆì •ì„± ë¬¸ì œë¡œ ì¸í•œ ê°•í•œ ë¶ˆë§Œì„ í‘œí˜„
- UX ê°œì„  ì œì•ˆ:
  â€¢ í†µí™” ì—°ê²° ì‹¤íŒ¨ ì‹œ "ì—°ê²° ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤" ëª…í™•í•œ ì˜¤ë¥˜ ë©”ì‹œì§€ í‘œì‹œ
  â€¢ ìë™ ì¬ì—°ê²° ì‹œë„ ê¸°ëŠ¥ê³¼ ì§„í–‰ ìƒíƒœ í‘œì‹œ
  â€¢ í†µí™” ì—°ê²° ìƒíƒœë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ” ì‹œê°ì  ì¸ë””ì¼€ì´í„° ì¶”ê°€
  â€¢ ì—°ê²° ì‹¤íŒ¨ ì‹œ "ë‹¤ì‹œ ì‹œë„" ë²„íŠ¼ì„ í¬ê²Œ í‘œì‹œí•˜ì—¬ ì‰½ê²Œ ì¬ì‹œë„ ê°€ëŠ¥í•˜ë„ë¡ í•¨

ì˜ˆì‹œ ë¶„ì„ 3:
- ë¦¬ë·°: "ì•Œëœ°í°ì‚¬ìš©ìë¼ ì´ìš©ì´ ë¶ˆê°€ëŠ¥í•œì§€ ëª¨ë¥¸ ìƒíƒœì—ì„œ ìš°ì„  íšŒì›ê°€ì…ì„ í–ˆê³  ë¡œê·¸ì¸ì´ ì•ˆë˜ë‹ˆ íƒˆí‡´ê°€ ì•ˆë˜ì–´"
- ë¬¸ì œ ìš”ì•½: ì‚¬ìš©ìê°€ "ì•Œëœ°í°ì‚¬ìš©ìë¼ ì´ìš©ì´ ë¶ˆê°€ëŠ¥í•œì§€ ëª¨ë¥¸ ìƒíƒœì—ì„œ íšŒì›ê°€ì…í–ˆëŠ”ë° ë¡œê·¸ì¸ì´ ì•ˆë˜ë‹ˆ íƒˆí‡´ê°€ ì•ˆë˜ì–´"ë¼ê³  í‘œí˜„í•˜ë©°, ì„œë¹„ìŠ¤ ì œì•½ ì‚¬í•­ì— ëŒ€í•œ ì‚¬ì „ ì•ˆë‚´ ë¶€ì¡± ë¬¸ì œë¥¼ ì§€ì 
- UX ê°œì„  ì œì•ˆ:
  â€¢ íšŒì›ê°€ì… ì²« í™”ë©´ì— "ì§€ì›ë˜ëŠ” í†µì‹ ì‚¬" ì•ˆë‚´ ë°°ë„ˆ ì¶”ê°€
  â€¢ í†µì‹ ì‚¬ ì„ íƒ ë‹¨ê³„ì—ì„œ ì•Œëœ°í° ì§€ì› ì—¬ë¶€ ì‹¤ì‹œê°„ í™•ì¸ ê¸°ëŠ¥
  â€¢ ë¡œê·¸ì¸ ì‹¤íŒ¨ ì‹œ "ì•Œëœ°í° ì‚¬ìš©ìëŠ” ì„œë¹„ìŠ¤ ì´ìš©ì´ ì œí•œë©ë‹ˆë‹¤" êµ¬ì²´ì  ì•ˆë‚´ ë©”ì‹œì§€
  â€¢ íƒˆí‡´ ë²„íŠ¼ì„ ë¡œê·¸ì¸ í™”ë©´ì—ë„ ë°°ì¹˜í•˜ì—¬ ì ‘ê·¼ì„± ê°œì„ 

ê¸°ìˆ ì  êµ¬í˜„ ë°©ë²•ì€ ì œì™¸í•˜ê³ , ìˆœìˆ˜ UX ê´€ì ì—ì„œì˜ ê°œì„  ë°©ì•ˆë§Œ ì œì‹œí•˜ì„¸ìš”.
ì‹¤ì œ ì‚¬ìš©ì ë¦¬ë·°ì—ì„œ ë°œê²¬ëœ ë¬¸ì œë§Œ ë¶„ì„í•˜ê³ , ê°€ìƒì˜ ë¬¸ì œëŠ” ë§Œë“¤ì§€ ë§ˆì„¸ìš”.
`;

    const response = await openai.chat.completions.create({
      model: "gpt-4o-mini", // Use mini model to reduce token usage
      messages: [
        {
          role: "system",
          content: "ë‹¹ì‹ ì€ UX ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ì ë¦¬ë·°ë¥¼ ë¶„ì„í•˜ì—¬ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ UX ê°œì„  ì œì•ˆì„ ìƒì„±í•©ë‹ˆë‹¤. ì¼ë°˜ì ì¸ ì œì•ˆ(ì˜ˆ: 'ì‚¬ìš©ì„± ê°œì„ ì´ í•„ìš”', 'ì¹œì ˆí•œ ì•ˆë‚´')ì´ ì•„ë‹Œ, ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ êµ¬ì²´ì ì¸ ìƒí™©ê³¼ ë¬¸ì œì ì„ ë°”íƒ•ìœ¼ë¡œ ëª…í™•í•œ í•´ê²° ë°©ì•ˆì„ ì œì‹œí•˜ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´, 'ì „í™” ë°›ì„ ë•Œ ì§„ë™ì´ ì•ˆ êº¼ì ¸ì„œ ë¶ˆí¸'ì´ë¼ëŠ” ë¦¬ë·°ì— ëŒ€í•´ì„œëŠ” 'ì„¤ì • ë©”ë‰´ì— í†µí™” ì¤‘ ì§„ë™ ìë™ ë„ê¸° í† ê¸€ ì¶”ê°€', 'í†µí™” í™”ë©´ì— ì§„ë™ on/off ë¹ ë¥¸ ë²„íŠ¼ ë°°ì¹˜' ë“±ì˜ êµ¬ì²´ì ì¸ UX ì†”ë£¨ì…˜ì„ ì œì•ˆí•˜ì„¸ìš”. ê¸°ìˆ ì  êµ¬í˜„ì€ ì œì™¸í•˜ê³  ìˆœìˆ˜ UX ê´€ì ì—ì„œ ì‘ë‹µí•˜ë©°, ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•íƒœë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."
        },
        {
          role: "user",
          content: prompt
        }
      ],
      max_tokens: 1500,
      temperature: 0.3,
      response_format: { type: "json_object" }
    });

    const result = response.choices[0].message.content;
    
    try {
      const parsedResult = JSON.parse(result || '{}');
      
      // Ensure the result has the expected structure
      if (parsedResult.insights && Array.isArray(parsedResult.insights)) {
        return parsedResult.insights;
      } else if (Array.isArray(parsedResult)) {
        return parsedResult;
      } else {
        console.warn('GPT returned unexpected HEART analysis format:', result);
        return [];
      }
    } catch (parseError) {
      console.error('Failed to parse GPT HEART analysis response:', parseError);
      return [];
    }
  } catch (error) {
    console.error('GPT HEART analysis error:', error);
    return [];
  }
}

export async function generateClusterLabel(keywords: string[]): Promise<string> {
  try {
    const prompt = `ë‹¤ìŒ í‚¤ì›Œë“œë“¤ì„ ë¶„ì„í•˜ì—¬ UX ê´€ì ì—ì„œ ì ì ˆí•œ í´ëŸ¬ìŠ¤í„° ì´ë¦„ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

í‚¤ì›Œë“œ: ${keywords.join(', ')}

í´ëŸ¬ìŠ¤í„° ì´ë¦„ì€ ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•´ì•¼ í•©ë‹ˆë‹¤:
1. UX/ì‚¬ìš©ì„± ê´€ì ì—ì„œ ì˜ë¯¸ ìˆëŠ” ì´ë¦„
2. ì‚¬ìš©ì ê²½í—˜ì˜ íŠ¹ì • ì˜ì—­ì„ ë‚˜íƒ€ë‚´ëŠ” ì´ë¦„
3. í•œêµ­ì–´ë¡œ 2-6ê¸€ì ë‚´ì™¸
4. êµ¬ì²´ì ì´ê³  ì§ê´€ì ì¸ ì´ë¦„

ì˜ˆì‹œ:
- ["ëŠê¹€", "íŠ•ê¹€", "ë©ˆì¶¤"] â†’ "ì•± ì•ˆì •ì„±"
- ["ë³µì¡", "ì–´ë ¤ì›€", "í—·ê°ˆë¦¼"] â†’ "ì‚¬ìš© í¸ì˜ì„±"
- ["ëŠë¦¼", "ë¡œë”©", "ëŒ€ê¸°"] â†’ "ì„±ëŠ¥ ë°˜ì‘ì„±"
- ["ë²„íŠ¼", "ë©”ë‰´", "í™”ë©´"] â†’ "ì¸í„°í˜ì´ìŠ¤"
- ["í†µí™”", "ì—°ê²°", "ìŒì„±"] â†’ "í†µí™” ê¸°ëŠ¥"

í´ëŸ¬ìŠ¤í„° ì´ë¦„ë§Œ ë°˜í™˜í•˜ì„¸ìš”:`;

    const response = await openai.chat.completions.create({
      model: "gpt-4o-mini", // the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
      messages: [{ role: "user", content: prompt }],
      max_tokens: 20,
      temperature: 0.3,
    });

    const label = response.choices[0].message.content?.trim() || `í‚¤ì›Œë“œ ê·¸ë£¹`;
    return label;
  } catch (error) {
    console.error('í´ëŸ¬ìŠ¤í„° ë¼ë²¨ ìƒì„± ì‹¤íŒ¨:', error);
    return `í‚¤ì›Œë“œ ê·¸ë£¹`;
  }
}

// Removed: generateKeywordNetworkWithGPT - keyword network analysis is no longer used

export async function analyzeReviewSentimentBatch(reviewTexts: string[]): Promise<('ê¸ì •' | 'ë¶€ì •' | 'ì¤‘ë¦½')[]> {
  const results: ('ê¸ì •' | 'ë¶€ì •' | 'ì¤‘ë¦½')[] = [];
  
  console.log(`Processing ${reviewTexts.length} reviews for sentiment analysis`);
  
  // Pre-filter with enhanced rule-based analysis to reduce GPT calls by 90%+
  const needsGPTAnalysis: { text: string; index: number }[] = [];
  
  for (let i = 0; i < reviewTexts.length; i++) {
    const reviewText = reviewTexts[i];
    const cacheKey = reviewText.trim().toLowerCase();
    
    // Check cache first
    if (sentimentCache.has(cacheKey)) {
      results[i] = sentimentCache.get(cacheKey)!;
      continue;
    }
    
    // Try enhanced rule-based analysis
    const ruleResult = tryRuleBasedAnalysis(reviewText);
    if (ruleResult) {
      results[i] = ruleResult;
      sentimentCache.set(cacheKey, ruleResult);
    } else {
      // Only queue for GPT if rule-based can't determine
      needsGPTAnalysis.push({ text: reviewText, index: i });
    }
  }
  
  const ruleResolved = results.filter(r => r).length;
  console.log(`Rule-based analysis resolved ${ruleResolved}/${reviewTexts.length} reviews (${Math.round(ruleResolved/reviewTexts.length*100)}%)`);
  
  // Process remaining reviews with GPT in parallel batches for maximum speed
  if (needsGPTAnalysis.length > 0) {
    console.log(`Processing ${needsGPTAnalysis.length} reviews with GPT in parallel batches`);
    
    const batchSize = 20; // Increased batch size
    const batches = [];
    
    // Create batches
    for (let i = 0; i < needsGPTAnalysis.length; i += batchSize) {
      batches.push(needsGPTAnalysis.slice(i, i + batchSize));
    }
    
    // Process all batches in parallel
    const batchPromises = batches.map(async (batch, batchIndex) => {
      try {
        const prompt = `ê°ì • ë¶„ì„: ë‹¤ìŒ ë¦¬ë·°ë“¤ì„ 'ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½'ìœ¼ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.

ê·œì¹™:
- ì „ì²´ ë§¥ë½ ìš°ì„  (ë‹¨ì¼ ê°ì • ë‹¨ì–´ë³´ë‹¤ ë¬¸ì¥ ì „ì²´ ì˜ë¯¸)
- ì ‘ì†ì‚¬('ê·¸ëŸ°ë°', 'í•˜ì§€ë§Œ') ë’¤ì˜ ë‚´ìš©ì´ ë” ì¤‘ìš”
- 'ì•ˆë˜ë‹¤', 'ëª»í•˜ë‹¤' ë“± = ê°•í•œ ë¶€ì •
- 'ê´œì°®ë‹¤', 'ë³´í†µ' ë“± = ì¤‘ë¦½

ë¦¬ë·°:
${batch.map((item, idx) => `${idx + 1}. ${item.text}`).join('\n')}

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{"sentiments": ["ê¸ì •", "ë¶€ì •", "ì¤‘ë¦½", ...]}`

        const response = await openai.chat.completions.create({
          model: "gpt-4o-mini",
          messages: [{ role: "user", content: prompt }],
          max_tokens: 200,
          temperature: 0,
          response_format: { type: "json_object" }
        });

        const result = JSON.parse(response.choices[0].message.content || '{}');
        const sentiments = result.sentiments || [];
        
        console.log(`Completed GPT batch ${batchIndex + 1}/${batches.length}`);
        return { batch, sentiments };
        
      } catch (error) {
        console.error(`GPT batch ${batchIndex + 1} error:`, error);
        return { batch, sentiments: batch.map(() => 'ì¤‘ë¦½') };
      }
    });
    
    // Wait for all batches to complete
    const batchResults = await Promise.all(batchPromises);
    
    // Process results
    for (const { batch, sentiments } of batchResults) {
      for (let j = 0; j < batch.length; j++) {
        const sentiment = sentiments[j] || 'ì¤‘ë¦½';
        const item = batch[j];
        results[item.index] = sentiment;
        sentimentCache.set(item.text.trim().toLowerCase(), sentiment);
      }
    }
  }
{"sentiments": ["ê¸ì •", "ë¶€ì •", "ì¤‘ë¦½", ...]}`;

        const response = await openai.chat.completions.create({
          model: "gpt-4o-mini",
          messages: [
            { role: "system", content: "ë‹¹ì‹ ì€ í•œêµ­ì–´ ë¦¬ë·° ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë¬¸ì¥ì˜ ì „ì²´ ë§¥ë½ê³¼ ê²°ë§ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ê°ì •ì„ ì •í™•íˆ íŒë‹¨í•´ì£¼ì„¸ìš”. ê¸ì •ì  ë‹¨ì–´ê°€ í¬í•¨ë˜ì–´ ìˆì–´ë„ ì „ì²´ ë§¥ë½ì´ ë¶€ì •ì ì´ë©´ 'ë¶€ì •'ìœ¼ë¡œ ë¶„ë¥˜í•˜ê³ , ì ‘ì†ì‚¬('ê·¸ëŸ°ë°', 'í•˜ì§€ë§Œ', 'ê·¼ë°') ë’¤ì˜ ë‚´ìš©ì„ ë” ì¤‘ìš”í•˜ê²Œ ê³ ë ¤í•´ì£¼ì„¸ìš”." },
            { role: "user", content: prompt }
          ],
          max_tokens: 100,
          temperature: 0,
          response_format: { type: "json_object" }
        });

        const result = JSON.parse(response.choices[0].message.content || '{}');
        const sentiments = result.sentiments || [];
        
        for (let j = 0; j < batch.length; j++) {
          const sentiment = sentiments[j] || 'ì¤‘ë¦½';
          const item = batch[j];
          results[item.index] = sentiment;
          sentimentCache.set(item.text.trim().toLowerCase(), sentiment);
        }
        
        console.log(`Processed GPT batch ${Math.ceil((i + batchSize) / batchSize)}/${Math.ceil(needsGPTAnalysis.length / batchSize)}`);
        
      } catch (error) {
        console.error(`GPT batch error:`, error);
        // Fallback to neutral for failed batch
        for (const item of batch) {
          results[item.index] = 'ì¤‘ë¦½';
        }
      }
    }
  }
  
  // Fill any remaining gaps
  for (let i = 0; i < reviewTexts.length; i++) {
    if (!results[i]) {
      results[i] = 'ì¤‘ë¦½';
    }
  }
  
  console.log(`Batch sentiment analysis completed: ${results.length} results`);
  return results;
}

export async function analyzeReviewSentimentWithGPT(reviewText: string): Promise<'ê¸ì •' | 'ë¶€ì •' | 'ì¤‘ë¦½'> {
  // Step 1: Check cache first
  const cacheKey = reviewText.trim().toLowerCase();
  if (sentimentCache.has(cacheKey)) {
    console.log(`Using cached sentiment for: ${reviewText.substring(0, 30)}...`);
    return sentimentCache.get(cacheKey)!;
  }

  // Step 2: Try rule-based analysis first (99% accuracy for clear cases)
  const ruleBasedResult = tryRuleBasedAnalysis(reviewText);
  if (ruleBasedResult) {
    sentimentCache.set(cacheKey, ruleBasedResult);
    console.log(`Rule-based sentiment: ${ruleBasedResult} for: ${reviewText.substring(0, 30)}...`);
    return ruleBasedResult;
  }

  // Step 3: Only use GPT for ambiguous cases
  try {
    const response = await openai.chat.completions.create({
      model: "gpt-4o-mini", // Use cheaper model for sentiment analysis
      messages: [
        {
          role: "system",
          content: "ë‹¹ì‹ ì€ í•œêµ­ì–´ ë¦¬ë·° ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë¬¸ì¥ì˜ ì „ì²´ ë§¥ë½ê³¼ ê²°ë§ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ê°ì •ì„ ì •í™•íˆ íŒë‹¨í•´ì£¼ì„¸ìš”. ê¸ì •ì  ë‹¨ì–´ê°€ í¬í•¨ë˜ì–´ ìˆì–´ë„ ì „ì²´ ë§¥ë½ì´ ë¶€ì •ì ì´ë©´ 'ë¶€ì •'ìœ¼ë¡œ ë¶„ë¥˜í•˜ê³ , ì ‘ì†ì‚¬('ê·¸ëŸ°ë°', 'í•˜ì§€ë§Œ', 'ê·¼ë°') ë’¤ì˜ ë‚´ìš©ì„ ë” ì¤‘ìš”í•˜ê²Œ ê³ ë ¤í•´ì£¼ì„¸ìš”."
        },
        {
          role: "user",
          content: `ë‹¤ìŒ ë¦¬ë·°ë¥¼ ì „ì²´ ë§¥ë½ê³¼ ê²°ë§ì„ ê³ ë ¤í•˜ì—¬ ë¶„ì„í•´ì£¼ì„¸ìš”:
"${reviewText}"

ë¶„ì„ ê·œì¹™:
- ë¬¸ì¥ì— 'ì¢‹ë‹¤', 'ë¹ ë¥´ë‹¤' ê°™ì€ ê¸ì • ë‹¨ì–´ê°€ ìˆì–´ë„ ì „ì²´ ë§¥ë½ì´ ë¶€ì •ì ì´ë©´ 'ë¶€ì •'
- 'ê·¸ëŸ°ë°', 'í•˜ì§€ë§Œ', 'ê·¼ë°' ë’¤ì— ì˜¤ëŠ” ë¶€ì •ì  ë‚´ìš©ì´ ë” ì¤‘ìš”í•¨
- 'ì•ˆë˜ë‹¤', 'ëª»í•˜ë‹¤', 'ì•ˆë¼ë‹¤' ë“±ì€ ê°•í•œ ë¶€ì • ì‹ í˜¸
- 'ê´œì°®ë‹¤', 'ë³´í†µ', 'ê·¸ëŸ­ì €ëŸ­' ë“±ì€ ì¤‘ë¦½ ì‹ í˜¸

ì‘ë‹µ: ê¸ì •/ë¶€ì •/ì¤‘ë¦½ ì¤‘ í•˜ë‚˜ë§Œ`
        }
      ],
      max_tokens: 10,
      temperature: 0   // Deterministic results
    });

    const result = response.choices[0].message.content?.trim();
    
    // Ensure the response is one of the expected values
    if (result === 'ê¸ì •' || result === 'ë¶€ì •' || result === 'ì¤‘ë¦½') {
      sentimentCache.set(cacheKey, result);
      console.log(`GPT sentiment: ${result} for: ${reviewText.substring(0, 30)}...`);
      return result;
    }
    
    // Fallback: if GPT doesn't return expected format, use basic keyword analysis
    console.warn(`GPT returned unexpected sentiment: ${result}, falling back to keyword analysis`);
    const fallbackResult = analyzeReviewSentimentFallback(reviewText);
    sentimentCache.set(cacheKey, fallbackResult);
    return fallbackResult;
    
  } catch (error) {
    console.error('OpenAI API error:', error);
    // Fallback to keyword-based analysis if GPT fails
    const fallbackResult = analyzeReviewSentimentFallback(reviewText);
    sentimentCache.set(cacheKey, fallbackResult);
    return fallbackResult;
  }
}

// Enhanced rule-based pre-filtering to avoid GPT calls for obvious cases
function tryRuleBasedAnalysis(text: string): 'ê¸ì •' | 'ë¶€ì •' | 'ì¤‘ë¦½' | null {
  const lowerText = text.toLowerCase();
  
  // Priority negative patterns - these override everything else
  const priorityNegativePatterns = [
    'ì•ˆë˜', 'ì•ˆë¼', 'ì•ˆë˜ì–´', 'ì•ˆë˜ë„¤', 'ì•ˆë˜ìš”', 'ì•ˆë¨', 'ì•ˆë˜ê³ ', 'ì•ˆë˜ë‹ˆ', 'ì•ˆë˜ëŠ”',
    'ì•ˆë˜ì„œ', 'ì•ˆë˜ë©´', 'ì•ˆë˜ê² ', 'ì•ˆë˜ì–', 'ì•ˆë˜ë‹¤', 'ì•ˆë˜ë‚˜', 'ì•ˆë˜ë“ ', 'ì•ˆë˜ì—ˆ',
    'ì•ˆë˜ì§€', 'ì•ˆë˜ë”', 'ì•ˆë˜ëŠ”êµ¬ë‚˜', 'ì•ˆë˜ëŠ”ë°', 'ì•ˆë˜ê¸¸ë˜', 'ì•ˆë˜ë˜ë°',
    'ê±°ì ˆ', 'ëª»í•˜ëŠ”', 'ì•ˆí•˜ëŠ”', 'ì•ˆë¼ëŠ”', 'ì¡°ì¹˜' // ì‚¬ìš©ì ìš”ì²­ í‚¤ì›Œë“œ ì¶”ê°€
  ];
  
  // Check for priority negative patterns first
  const hasPriorityNegative = priorityNegativePatterns.some(pattern => lowerText.includes(pattern));
  if (hasPriorityNegative) {
    return 'ë¶€ì •';
  }
  
  // Comprehensive negative indicators (95%+ confidence)
  const strongNegativePatterns = [
    'ìµœì•…', 'í˜•í¸ì—†', 'ë³„ë¡œ', 'ì§œì¦', 'í™”ë‚¨', 'ì‹¤ë§', 'ëª»í•˜ê² ', 'ì‹«ì–´', 'ë‚˜ì¨', 'êµ¬ë ¤', 'ì‚­ì œ',
    'ì—ëŸ¬', 'ì˜¤ë¥˜', 'ë²„ê·¸', 'ë¬¸ì œ', 'ê³ ì¥', 'ë¨¹í†µ', 'ë ‰', 'ëŠê¹€', 'ëŠë ¤', 'ë‹µë‹µ', 'ê·€ì°®',
    'ë¶ˆí¸', 'ë‹¨ì ', 'ì•„ì‰¬ìš´', 'ë¶ˆë§Œ', 'ìŠ¤íŠ¸ë ˆìŠ¤', 'í˜ë“¤', 'ì–´ë µ', 'ë³µì¡', 'ë Œë”©', 'ëŠë¦¼',
    'ëŠì–´', 'íŠ•ê²¨', 'ë¨¹í†µ', 'ë©ˆì¶¤', 'ê°•ì œ', 'ê´‘ê³ ', 'ì°¨ë‹¨', 'ê³¼ì—´', 'ë°©í•´', 'ê±°ìŠ¬ë¦¼',
    'ì§ê´€', 'í˜•í¸ì—†', 'êµ¬ë¦¬', 'ë‹µë‹µ', 'ë‹µì—†', 'ë‹µë³€ì—†', 'ì“°ë ˆê¸°', 'ëª»ì“°', 'ë¶ˆê°€ëŠ¥'
  ];
  
  // Comprehensive positive indicators (95%+ confidence)  
  const strongPositivePatterns = [
    'ìµœê³ ', 'ëŒ€ë°•', 'ì™„ë²½', 'í›Œë¥­', 'ë©‹ì ¸', 'ì¢‹ì•„', 'ì¢‹ë„¤', 'ì¢‹ìŒ', 'ì¢‹ë‹¤', 'ì¢‹ìŠµë‹ˆë‹¤',
    'í¸ë¦¬', 'í¸í•´', 'ë§Œì¡±', 'ì¶”ì²œ', 'ê°ì‚¬', 'ê³ ë§ˆì›Œ', 'ìœ ìš©', 'ë„ì›€', 'ë¹ ë¦„', 'ë¹¨ë¼',
    'ì‰¬ì›Œ', 'ê°„ë‹¨', 'ëŒ€ë‹¨', 'ë†€ë¼', 'ê°ë™', 'í¸ì•ˆ', 'ì•ˆì „', 'ë“ ë“ ', 'ë¯¿ìŒ', 'ì‹ ë¢°',
    'íš¨ê³¼', 'ì™„ì „', 'ìš°ìˆ˜', 'ë›°ì–´', 'ì •í™•', 'ê¹”ë”', 'ê¹¨ë—', 'ì„ ëª…', 'ë¶€ë“œëŸ½', 'ë§¤ë„'
  ];
  
  // Count positive and negative indicators
  const negativeCount = strongNegativePatterns.filter(pattern => lowerText.includes(pattern)).length;
  const positiveCount = strongPositivePatterns.filter(pattern => lowerText.includes(pattern)).length;
  
  // Clear cases with multiple indicators
  if (negativeCount >= 2) return 'ë¶€ì •';
  if (positiveCount >= 2) return 'ê¸ì •';
  
  // Single strong indicator cases
  if (negativeCount > 0 && positiveCount === 0) return 'ë¶€ì •';
  if (positiveCount > 0 && negativeCount === 0) return 'ê¸ì •';
  
  // Length-based analysis for very short texts
  if (text.length < 10) {
    return 'ì¤‘ë¦½';
  }
  
  // Rating-based analysis for app reviews
  const ratingMatch = text.match(/(\d+)ì |(\d+)ì„±|(\d+)ë³„|rating[:\s]*(\d+)/i);
  if (ratingMatch) {
    const rating = parseInt(ratingMatch[1] || ratingMatch[2] || ratingMatch[3] || ratingMatch[4]);
    if (rating >= 4) return 'ê¸ì •';
    if (rating <= 2) return 'ë¶€ì •';
    if (rating === 3) return 'ì¤‘ë¦½';
  }
  
  // Length-based neutral detection
  if (text.trim().length < 5) return 'ì¤‘ë¦½';
  
  // Question-only reviews
  if (text.trim().endsWith('?') && text.split('?').length <= 2) return 'ì¤‘ë¦½';
  
  // Context-aware analysis for conjunctions (ê·¸ëŸ°ë°, í•˜ì§€ë§Œ, ê·¼ë°)
  const conjunctions = ['ê·¸ëŸ°ë°', 'í•˜ì§€ë§Œ', 'ê·¼ë°', 'ê·¸ëŸ¬ë‚˜', 'í•˜ì§€ë§Œì„œë„', 'ê·¸ì¹˜ë§Œ'];
  const hasConjunction = conjunctions.some(conj => lowerText.includes(conj));
  
  if (hasConjunction) {
    // Split by conjunction and analyze the latter part more heavily
    for (const conj of conjunctions) {
      if (lowerText.includes(conj)) {
        const parts = text.split(conj);
        if (parts.length > 1) {
          const latterPart = parts[parts.length - 1].toLowerCase();
          const latterNegativeCount = strongNegativePatterns.filter(pattern => latterPart.includes(pattern)).length;
          const latterPositiveCount = strongPositivePatterns.filter(pattern => latterPart.includes(pattern)).length;
          
          // If latter part is clearly negative, classify as negative
          if (latterNegativeCount > 0 && latterPositiveCount === 0) return 'ë¶€ì •';
          if (latterPositiveCount > 0 && latterNegativeCount === 0) return 'ê¸ì •';
          
          // Weight the latter part more heavily
          if (latterNegativeCount > latterPositiveCount) return 'ë¶€ì •';
          if (latterPositiveCount > latterNegativeCount) return 'ê¸ì •';
        }
        break;
      }
    }
  }

  // Mixed sentiment with neutral tendency
  if (negativeCount > 0 && positiveCount > 0) {
    if (Math.abs(negativeCount - positiveCount) <= 1) return 'ì¤‘ë¦½';
  }
  
  // If no clear indicators, return null to trigger GPT analysis
  return null;
}

function analyzeReviewSentimentFallback(text: string): 'ê¸ì •' | 'ë¶€ì •' | 'ì¤‘ë¦½' {
  const lowerText = text.toLowerCase();
  
  // Priority negative keywords
  const priorityNegativeKeywords = ['ë¶ˆí¸', 'ë‹¨ì ', 'ì•„ì‰¬ìš´ ì ', 'ë¶ˆí¸í•œ ì ', 'ë¶ˆë§Œ', 'ì‹«ì€ ì '];
  const hasPriorityNegative = priorityNegativeKeywords.some(keyword => lowerText.includes(keyword));
  
  if (hasPriorityNegative) {
    return 'ë¶€ì •';
  }
  
  // Enhanced negative keywords
  const negativeKeywords = [
    'ì•ˆë¨', 'ì•ˆë˜ë„¤', 'ëª»í•˜', 'ì•ˆí•´', 'ì‹¤íŒ¨', 'ì—ëŸ¬', 'ì˜¤ë¥˜', 'ë²„ê·¸', 'ë¬¸ì œ', 'ê³ ì¥',
    'ëŠë ¤', 'ëŠë¦¼', 'ë‹µë‹µ', 'ì§œì¦', 'í™”ë‚¨', 'ì‹¤ë§', 'ìµœì•…', 'ë³„ë¡œ', 'êµ¬ë ¤', 'í˜•í¸ì—†',
    'ë‚˜ê°€ë²„ë¦¼', 'êº¼ì ¸', 'ë©ˆì¶¤', 'ë¨¹í†µ', 'ë ‰', 'ëŠê¹€', 'ì•ˆì¢‹', 'ë‚˜ì¨', 'ì‹«ì–´',
    'ê·€ì°®', 'ìŠ¤íŠ¸ë ˆìŠ¤', 'í˜ë“¤', 'ì–´ë µ', 'ë³µì¡', 'ê´‘ê³  ë§', 'ê°•ì œ', 'ëœ¨ê±°ì›€', 'ë°©í•´',
    'ì—†ìŒ', 'ì°¨ë‹¨ ì•ˆ', 'ê³¼ì—´', 'ê±°ìŠ¬ë¦¼'
  ];
  
  // Positive keywords
  const positiveKeywords = [
    'ì¢‹ì•„', 'ì¢‹ë„¤', 'ì¢‹ìŒ', 'í›Œë¥­', 'ìµœê³ ', 'ëŒ€ë°•', 'ì™„ë²½', 'ë©‹ì ¸', 'ì˜ˆì˜', 'ì´ì˜',
    'í¸ë¦¬', 'í¸í•´', 'ì‰¬ì›Œ', 'ê°„ë‹¨', 'ë¹ ë¦„', 'ë¹¨ë¼', 'ë§Œì¡±', 'ì¶”ì²œ', 'ê°ì‚¬', 'ê³ ë§ˆì›Œ',
    'ìœ ìš©', 'ë„ì›€', 'íš¨ê³¼', 'ì„±ê³µ', 'ì˜ë¨', 'ì˜ë˜ë„¤', 'ê´œì°®', 'ë¬´ë‚œ', 'ì ë‹¹'
  ];
  
  // Neutral keywords
  const neutralKeywords = [
    'ê·¸ëƒ¥', 'ë³´í†µ', 'í‰ë²”', 'ì¼ë°˜ì ', 'ê·¸ëŸ­ì €ëŸ­', 'ë‚˜ë¦„', 'ì ì ˆ', 'ë¬´ë‚œ',
    'ì°¸ê³ ', 'ì •ë³´', 'ì•ˆë‚´', 'ì„¤ëª…', 'ì‚¬ìš©ë²•', 'ë°©ë²•', 'ê¸°ëŠ¥', 'ì—…ë°ì´íŠ¸'
  ];
  
  const negativeCount = negativeKeywords.filter(keyword => lowerText.includes(keyword)).length;
  const positiveCount = positiveKeywords.filter(keyword => lowerText.includes(keyword)).length;
  const neutralCount = neutralKeywords.filter(keyword => lowerText.includes(keyword)).length;
  
  // Classification logic
  if (negativeCount >= 2 || (negativeCount > 0 && positiveCount === 0)) {
    return 'ë¶€ì •';
  } else if (positiveCount > negativeCount && neutralCount <= 1) {
    return 'ê¸ì •';
  } else if (neutralCount >= 2 || (neutralCount > 0 && positiveCount === 0 && negativeCount === 0)) {
    return 'ì¤‘ë¦½';
  } else if (positiveCount === negativeCount && positiveCount > 0) {
    return 'ì¤‘ë¦½';
  } else if (positiveCount > 0) {
    return 'ê¸ì •';
  } else {
    return 'ì¤‘ë¦½';
  }
}