import OpenAI from "openai";

// the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// Cache for GPT sentiment analysis results to avoid duplicate API calls
const sentimentCache = new Map<string, 'ê¸ì •' | 'ë¶€ì •' | 'ì¤‘ë¦½'>();

// Batch processing for multiple reviews to reduce API calls
// GPT-based HEART framework analysis
export async function analyzeHeartFrameworkWithGPT(reviews: any[]): Promise<any[]> {
  if (!reviews || reviews.length === 0) {
    return [];
  }

  try {
    // Prepare review texts for analysis
    const reviewTexts = reviews.map(review => ({
      content: review.content,
      rating: review.rating,
      source: review.source
    }));

    // Create prompt for HEART framework analysis
    const prompt = `
ë‹¤ìŒ ë¦¬ë·°ë“¤ì„ HEART í”„ë ˆì„ì›Œí¬ì— ë”°ë¼ ë¶„ì„í•˜ì—¬ UX ê°œì„  ì œì•ˆì„ ìƒì„±í•´ì£¼ì„¸ìš”.

HEART í”„ë ˆì„ì›Œí¬:
- Happiness: ì‚¬ìš©ì ë§Œì¡±ë„ ë° ê°ì •
- Engagement: ì‚¬ìš©ì ì°¸ì—¬ë„ ë° í™œë™ ìˆ˜ì¤€
- Adoption: ìƒˆë¡œìš´ ê¸°ëŠ¥ ì±„íƒ ë° ì‚¬ìš© ì‹œì‘
- Retention: ì‚¬ìš©ì ìœ ì§€ ë° ì¬ì‚¬ìš©
- Task Success: ì‘ì—… ì™„ë£Œ ë° ì„±ê³µë¥ 

ë¦¬ë·° ë°ì´í„°:
${reviewTexts.map((review, index) => `${index + 1}. [${review.source}] í‰ì : ${review.rating}/5
ë‚´ìš©: ${review.content}`).join('\n\n')}

ë¶„ì„ ê²°ê³¼ë¥¼ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”:
{
  "insights": [
    {
      "category": "happiness|engagement|adoption|retention|task_success",
      "title": "ğŸ”´ Critical | HEART: [category] | [ë¬¸ì œìœ í˜•] ([ê±´ìˆ˜]ê±´)",
      "problem_summary": "ì‹¤ì œ ì‚¬ìš©ì í‘œí˜„ì„ ì¸ìš©í•˜ë©° êµ¬ì²´ì ì¸ ë¬¸ì œì  ì„¤ëª…",
      "ux_suggestions": "êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ UX ê°œì„  ì œì•ˆ (3-5ê°€ì§€)",
      "priority": "critical|major|minor",
      "mention_count": ê±´ìˆ˜,
      "trend": "stable"
    }
  ]
}

ìš°ì„ ìˆœìœ„ ê¸°ì¤€:
- Critical: í•µì‹¬ ê¸°ëŠ¥ ì˜¤ë¥˜, ì•± í¬ë˜ì‹œ, ì‘ì—… ì‹¤íŒ¨ (3ê±´ ì´ìƒ)
- Major: ì£¼ìš” ë¶ˆí¸ì‚¬í•­, ì‚¬ìš©ì„± ë¬¸ì œ (2ê±´ ì´ìƒ)
- Minor: ê°œì„  ì œì•ˆ, ì†Œì†Œí•œ ë¶ˆí¸ (1ê±´)

ì‹¤ì œ ì‚¬ìš©ì ë¦¬ë·°ì—ì„œ ë°œê²¬ëœ ë¬¸ì œë§Œ ë¶„ì„í•˜ê³ , ê°€ìƒì˜ ë¬¸ì œëŠ” ë§Œë“¤ì§€ ë§ˆì„¸ìš”.
`;

    const response = await openai.chat.completions.create({
      model: "gpt-4o", // Use more powerful model for complex analysis
      messages: [
        {
          role: "system",
          content: "ë‹¹ì‹ ì€ UX ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ì ë¦¬ë·°ë¥¼ ë¶„ì„í•˜ì—¬ ì‹¤ìš©ì ì¸ UX ê°œì„  ì œì•ˆì„ ìƒì„±í•©ë‹ˆë‹¤. ì‘ë‹µì€ ë°˜ë“œì‹œ ìœ íš¨í•œ JSON ë°°ì—´ í˜•íƒœë¡œ í•´ì£¼ì„¸ìš”."
        },
        {
          role: "user",
          content: prompt
        }
      ],
      max_tokens: 2000,
      temperature: 0.3,
      response_format: { type: "json_object" }
    });

    const result = response.choices[0].message.content;
    
    try {
      const parsedResult = JSON.parse(result || '{}');
      
      // Ensure the result has the expected structure
      if (parsedResult.insights && Array.isArray(parsedResult.insights)) {
        return parsedResult.insights;
      } else if (Array.isArray(parsedResult)) {
        return parsedResult;
      } else {
        console.warn('GPT returned unexpected HEART analysis format:', result);
        return [];
      }
    } catch (parseError) {
      console.error('Failed to parse GPT HEART analysis response:', parseError);
      return [];
    }
    
  } catch (error) {
    console.error('OpenAI API error in HEART analysis:', error);
    return [];
  }
}

// GPT-based word cloud analysis
export async function generateWordCloudWithGPT(reviews: any[]): Promise<{
  positive: { word: string; frequency: number; sentiment: string }[];
  negative: { word: string; frequency: number; sentiment: string }[];
}> {
  if (!reviews || reviews.length === 0) {
    return { positive: [], negative: [] };
  }

  try {
    // Separate reviews by sentiment
    const positiveReviews = reviews.filter(r => r.sentiment === 'ê¸ì •');
    const negativeReviews = reviews.filter(r => r.sentiment === 'ë¶€ì •');

    // Create prompts for positive and negative word extraction
    const positivePrompt = `
ë‹¤ìŒ ê¸ì •ì ì¸ ë¦¬ë·°ë“¤ì—ì„œ ìì£¼ ì–¸ê¸‰ë˜ëŠ” ì¤‘ìš”í•œ í•œêµ­ì–´ ë‹¨ì–´ 10ê°œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ê¸ì • ë¦¬ë·°:
${positiveReviews.map((review, index) => `${index + 1}. ${review.content}`).join('\n')}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”:
{
  "words": [
    {"word": "ë‹¨ì–´", "frequency": ë¹ˆë„ìˆ˜, "sentiment": "positive"}
  ]
}

ì¡°ê±´:
- ì˜ë¯¸ ìˆëŠ” ëª…ì‚¬ë‚˜ í˜•ìš©ì‚¬ë§Œ ì„ íƒ
- í•œêµ­ì–´ ë‹¨ì–´ë§Œ ì¶”ì¶œ
- ë¹ˆë„ìˆ˜ëŠ” ì‹¤ì œ ì–¸ê¸‰ íšŸìˆ˜ ê¸°ë°˜
- ì´ 10ê°œ ë‹¨ì–´ ì„ íƒ
`;

    const negativePrompt = `
ë‹¤ìŒ ë¶€ì •ì ì¸ ë¦¬ë·°ë“¤ì—ì„œ ìì£¼ ì–¸ê¸‰ë˜ëŠ” ì¤‘ìš”í•œ í•œêµ­ì–´ ë‹¨ì–´ 10ê°œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ë¶€ì • ë¦¬ë·°:
${negativeReviews.map((review, index) => `${index + 1}. ${review.content}`).join('\n')}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”:
{
  "words": [
    {"word": "ë‹¨ì–´", "frequency": ë¹ˆë„ìˆ˜, "sentiment": "negative"}
  ]
}

ì¡°ê±´:
- ì˜ë¯¸ ìˆëŠ” ëª…ì‚¬ë‚˜ í˜•ìš©ì‚¬ë§Œ ì„ íƒ
- í•œêµ­ì–´ ë‹¨ì–´ë§Œ ì¶”ì¶œ
- ë¹ˆë„ìˆ˜ëŠ” ì‹¤ì œ ì–¸ê¸‰ íšŸìˆ˜ ê¸°ë°˜
- ì´ 10ê°œ ë‹¨ì–´ ì„ íƒ
`;

    // Process positive words
    let positiveWords: any[] = [];
    if (positiveReviews.length > 0) {
      const positiveResponse = await openai.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [
          {
            role: "system",
            content: "ë‹¹ì‹ ì€ í•œêµ­ì–´ í…ìŠ¤íŠ¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë¦¬ë·°ì—ì„œ ì˜ë¯¸ ìˆëŠ” í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."
          },
          {
            role: "user",
            content: positivePrompt
          }
        ],
        max_tokens: 500,
        temperature: 0.3,
        response_format: { type: "json_object" }
      });

      try {
        const positiveResult = JSON.parse(positiveResponse.choices[0].message.content || '{}');
        positiveWords = positiveResult.words || [];
      } catch (error) {
        console.error('Failed to parse positive words:', error);
      }
    }

    // Process negative words
    let negativeWords: any[] = [];
    if (negativeReviews.length > 0) {
      const negativeResponse = await openai.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [
          {
            role: "system",
            content: "ë‹¹ì‹ ì€ í•œêµ­ì–´ í…ìŠ¤íŠ¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë¦¬ë·°ì—ì„œ ì˜ë¯¸ ìˆëŠ” í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."
          },
          {
            role: "user",
            content: negativePrompt
          }
        ],
        max_tokens: 500,
        temperature: 0.3,
        response_format: { type: "json_object" }
      });

      try {
        const negativeResult = JSON.parse(negativeResponse.choices[0].message.content || '{}');
        negativeWords = negativeResult.words || [];
      } catch (error) {
        console.error('Failed to parse negative words:', error);
      }
    }

    return {
      positive: positiveWords,
      negative: negativeWords
    };

  } catch (error) {
    console.error('OpenAI API error in word cloud analysis:', error);
    return { positive: [], negative: [] };
  }
}

export async function analyzeReviewSentimentBatch(reviewTexts: string[]): Promise<('ê¸ì •' | 'ë¶€ì •' | 'ì¤‘ë¦½')[]> {
  const results: ('ê¸ì •' | 'ë¶€ì •' | 'ì¤‘ë¦½')[] = [];
  
  console.log(`Processing ${reviewTexts.length} reviews for sentiment analysis`);
  
  // Pre-filter with enhanced rule-based analysis to reduce GPT calls by 90%+
  const needsGPTAnalysis: { text: string; index: number }[] = [];
  
  for (let i = 0; i < reviewTexts.length; i++) {
    const reviewText = reviewTexts[i];
    const cacheKey = reviewText.trim().toLowerCase();
    
    // Check cache first
    if (sentimentCache.has(cacheKey)) {
      results[i] = sentimentCache.get(cacheKey)!;
      continue;
    }
    
    // Try enhanced rule-based analysis
    const ruleResult = tryRuleBasedAnalysis(reviewText);
    if (ruleResult) {
      results[i] = ruleResult;
      sentimentCache.set(cacheKey, ruleResult);
    } else {
      // Only queue for GPT if rule-based can't determine
      needsGPTAnalysis.push({ text: reviewText, index: i });
    }
  }
  
  const ruleResolved = results.filter(r => r).length;
  console.log(`Rule-based analysis resolved ${ruleResolved}/${reviewTexts.length} reviews (${Math.round(ruleResolved/reviewTexts.length*100)}%)`);
  
  // Process remaining reviews with GPT in batches
  if (needsGPTAnalysis.length > 0) {
    console.log(`Processing ${needsGPTAnalysis.length} reviews with GPT`);
    
    const batchSize = 15;
    for (let i = 0; i < needsGPTAnalysis.length; i += batchSize) {
      const batch = needsGPTAnalysis.slice(i, i + batchSize);
      
      try {
        const prompt = `ê°ì • ë¶„ì„: ${batch.map((item, idx) => `${idx + 1}. ${item.text}`).join('\n')}
        
ì‘ë‹µ í˜•ì‹: {"sentiments": ["ê¸ì •", "ë¶€ì •", "ì¤‘ë¦½"]}
ê·œì¹™: ì•ˆë˜/ë¶ˆí¸/ë¬¸ì œâ†’ë¶€ì •, ì¢‹/ë§Œì¡±/í¸ë¦¬â†’ê¸ì •, ì• ë§¤â†’ì¤‘ë¦½`;

        const response = await openai.chat.completions.create({
          model: "gpt-4o-mini",
          messages: [
            { role: "system", content: "í•œêµ­ì–´ ê°ì • ë¶„ì„ ì „ë¬¸ê°€. ë¹ ë¥´ê³  ì •í™•í•œ ë¶„ë¥˜." },
            { role: "user", content: prompt }
          ],
          max_tokens: 100,
          temperature: 0,
          response_format: { type: "json_object" }
        });

        const result = JSON.parse(response.choices[0].message.content || '{}');
        const sentiments = result.sentiments || [];
        
        for (let j = 0; j < batch.length; j++) {
          const sentiment = sentiments[j] || 'ì¤‘ë¦½';
          const item = batch[j];
          results[item.index] = sentiment;
          sentimentCache.set(item.text.trim().toLowerCase(), sentiment);
        }
        
        console.log(`Processed GPT batch ${Math.ceil((i + batchSize) / batchSize)}/${Math.ceil(needsGPTAnalysis.length / batchSize)}`);
        
      } catch (error) {
        console.error(`GPT batch error:`, error);
        // Fallback to neutral for failed batch
        for (const item of batch) {
          results[item.index] = 'ì¤‘ë¦½';
        }
      }
    }
  }
  
  // Fill any remaining gaps
  for (let i = 0; i < reviewTexts.length; i++) {
    if (!results[i]) {
      results[i] = 'ì¤‘ë¦½';
    }
  }
  
  console.log(`Batch sentiment analysis completed: ${results.length} results`);
  return results;
}

export async function analyzeReviewSentimentWithGPT(reviewText: string): Promise<'ê¸ì •' | 'ë¶€ì •' | 'ì¤‘ë¦½'> {
  // Step 1: Check cache first
  const cacheKey = reviewText.trim().toLowerCase();
  if (sentimentCache.has(cacheKey)) {
    console.log(`Using cached sentiment for: ${reviewText.substring(0, 30)}...`);
    return sentimentCache.get(cacheKey)!;
  }

  // Step 2: Try rule-based analysis first (99% accuracy for clear cases)
  const ruleBasedResult = tryRuleBasedAnalysis(reviewText);
  if (ruleBasedResult) {
    sentimentCache.set(cacheKey, ruleBasedResult);
    console.log(`Rule-based sentiment: ${ruleBasedResult} for: ${reviewText.substring(0, 30)}...`);
    return ruleBasedResult;
  }

  // Step 3: Only use GPT for ambiguous cases
  try {
    const response = await openai.chat.completions.create({
      model: "gpt-4o-mini", // Use cheaper model for sentiment analysis
      messages: [
        {
          role: "system",
          content: "í•œêµ­ì–´ ê°ì • ë¶„ì„. ì‘ë‹µ: ê¸ì •/ë¶€ì •/ì¤‘ë¦½ ì¤‘ í•˜ë‚˜ë§Œ"
        },
        {
          role: "user",
          content: reviewText
        }
      ],
      max_tokens: 5, // Reduce to minimum needed
      temperature: 0   // Deterministic results
    });

    const result = response.choices[0].message.content?.trim();
    
    // Ensure the response is one of the expected values
    if (result === 'ê¸ì •' || result === 'ë¶€ì •' || result === 'ì¤‘ë¦½') {
      sentimentCache.set(cacheKey, result);
      console.log(`GPT sentiment: ${result} for: ${reviewText.substring(0, 30)}...`);
      return result;
    }
    
    // Fallback: if GPT doesn't return expected format, use basic keyword analysis
    console.warn(`GPT returned unexpected sentiment: ${result}, falling back to keyword analysis`);
    const fallbackResult = analyzeReviewSentimentFallback(reviewText);
    sentimentCache.set(cacheKey, fallbackResult);
    return fallbackResult;
    
  } catch (error) {
    console.error('OpenAI API error:', error);
    // Fallback to keyword-based analysis if GPT fails
    const fallbackResult = analyzeReviewSentimentFallback(reviewText);
    sentimentCache.set(cacheKey, fallbackResult);
    return fallbackResult;
  }
}

// Enhanced rule-based pre-filtering to avoid GPT calls for obvious cases
function tryRuleBasedAnalysis(text: string): 'ê¸ì •' | 'ë¶€ì •' | 'ì¤‘ë¦½' | null {
  const lowerText = text.toLowerCase();
  
  // Priority negative patterns - these override everything else
  const priorityNegativePatterns = [
    'ì•ˆë˜', 'ì•ˆë¼', 'ì•ˆë˜ì–´', 'ì•ˆë˜ë„¤', 'ì•ˆë˜ìš”', 'ì•ˆë¨', 'ì•ˆë˜ê³ ', 'ì•ˆë˜ë‹ˆ', 'ì•ˆë˜ëŠ”',
    'ì•ˆë˜ì„œ', 'ì•ˆë˜ë©´', 'ì•ˆë˜ê² ', 'ì•ˆë˜ì–', 'ì•ˆë˜ë‹¤', 'ì•ˆë˜ë‚˜', 'ì•ˆë˜ë“ ', 'ì•ˆë˜ì—ˆ',
    'ì•ˆë˜ì§€', 'ì•ˆë˜ë”', 'ì•ˆë˜ëŠ”êµ¬ë‚˜', 'ì•ˆë˜ëŠ”ë°', 'ì•ˆë˜ê¸¸ë˜', 'ì•ˆë˜ë˜ë°'
  ];
  
  // Check for priority negative patterns first
  const hasPriorityNegative = priorityNegativePatterns.some(pattern => lowerText.includes(pattern));
  if (hasPriorityNegative) {
    return 'ë¶€ì •';
  }
  
  // Comprehensive negative indicators (95%+ confidence)
  const strongNegativePatterns = [
    'ìµœì•…', 'í˜•í¸ì—†', 'ë³„ë¡œ', 'ì§œì¦', 'í™”ë‚¨', 'ì‹¤ë§', 'ëª»í•˜ê² ', 'ì‹«ì–´', 'ë‚˜ì¨', 'êµ¬ë ¤', 'ì‚­ì œ',
    'ì—ëŸ¬', 'ì˜¤ë¥˜', 'ë²„ê·¸', 'ë¬¸ì œ', 'ê³ ì¥', 'ë¨¹í†µ', 'ë ‰', 'ëŠê¹€', 'ëŠë ¤', 'ë‹µë‹µ', 'ê·€ì°®',
    'ë¶ˆí¸', 'ë‹¨ì ', 'ì•„ì‰¬ìš´', 'ë¶ˆë§Œ', 'ìŠ¤íŠ¸ë ˆìŠ¤', 'í˜ë“¤', 'ì–´ë µ', 'ë³µì¡', 'ë Œë”©', 'ëŠë¦¼',
    'ëŠì–´', 'íŠ•ê²¨', 'ë¨¹í†µ', 'ë©ˆì¶¤', 'ê°•ì œ', 'ê´‘ê³ ', 'ì°¨ë‹¨', 'ê³¼ì—´', 'ë°©í•´', 'ê±°ìŠ¬ë¦¼',
    'ì§ê´€', 'í˜•í¸ì—†', 'êµ¬ë¦¬', 'ë‹µë‹µ', 'ë‹µì—†', 'ë‹µë³€ì—†', 'ì“°ë ˆê¸°', 'ëª»ì“°', 'ë¶ˆê°€ëŠ¥'
  ];
  
  // Comprehensive positive indicators (95%+ confidence)  
  const strongPositivePatterns = [
    'ìµœê³ ', 'ëŒ€ë°•', 'ì™„ë²½', 'í›Œë¥­', 'ë©‹ì ¸', 'ì¢‹ì•„', 'ì¢‹ë„¤', 'ì¢‹ìŒ', 'ì¢‹ë‹¤', 'ì¢‹ìŠµë‹ˆë‹¤',
    'í¸ë¦¬', 'í¸í•´', 'ë§Œì¡±', 'ì¶”ì²œ', 'ê°ì‚¬', 'ê³ ë§ˆì›Œ', 'ìœ ìš©', 'ë„ì›€', 'ë¹ ë¦„', 'ë¹¨ë¼',
    'ì‰¬ì›Œ', 'ê°„ë‹¨', 'ëŒ€ë‹¨', 'ë†€ë¼', 'ê°ë™', 'í¸ì•ˆ', 'ì•ˆì „', 'ë“ ë“ ', 'ë¯¿ìŒ', 'ì‹ ë¢°',
    'íš¨ê³¼', 'ì™„ì „', 'ìš°ìˆ˜', 'ë›°ì–´', 'ì •í™•', 'ê¹”ë”', 'ê¹¨ë—', 'ì„ ëª…', 'ë¶€ë“œëŸ½', 'ë§¤ë„'
  ];
  
  // Count positive and negative indicators
  const negativeCount = strongNegativePatterns.filter(pattern => lowerText.includes(pattern)).length;
  const positiveCount = strongPositivePatterns.filter(pattern => lowerText.includes(pattern)).length;
  
  // Clear cases with multiple indicators
  if (negativeCount >= 2) return 'ë¶€ì •';
  if (positiveCount >= 2) return 'ê¸ì •';
  
  // Single strong indicator cases
  if (negativeCount > 0 && positiveCount === 0) return 'ë¶€ì •';
  if (positiveCount > 0 && negativeCount === 0) return 'ê¸ì •';
  
  // Rating-based analysis for app reviews
  const ratingMatch = text.match(/(\d+)ì |(\d+)ì„±|(\d+)ë³„|rating[:\s]*(\d+)/i);
  if (ratingMatch) {
    const rating = parseInt(ratingMatch[1] || ratingMatch[2] || ratingMatch[3] || ratingMatch[4]);
    if (rating >= 4) return 'ê¸ì •';
    if (rating <= 2) return 'ë¶€ì •';
    if (rating === 3) return 'ì¤‘ë¦½';
  }
  
  // Length-based neutral detection
  if (text.trim().length < 5) return 'ì¤‘ë¦½';
  
  // Question-only reviews
  if (text.trim().endsWith('?') && text.split('?').length <= 2) return 'ì¤‘ë¦½';
  
  // Mixed sentiment with neutral tendency
  if (negativeCount > 0 && positiveCount > 0) {
    if (Math.abs(negativeCount - positiveCount) <= 1) return 'ì¤‘ë¦½';
  }
  
  // If no clear indicators, return null to trigger GPT analysis
  return null;
}

function analyzeReviewSentimentFallback(text: string): 'ê¸ì •' | 'ë¶€ì •' | 'ì¤‘ë¦½' {
  const lowerText = text.toLowerCase();
  
  // Priority negative keywords
  const priorityNegativeKeywords = ['ë¶ˆí¸', 'ë‹¨ì ', 'ì•„ì‰¬ìš´ ì ', 'ë¶ˆí¸í•œ ì ', 'ë¶ˆë§Œ', 'ì‹«ì€ ì '];
  const hasPriorityNegative = priorityNegativeKeywords.some(keyword => lowerText.includes(keyword));
  
  if (hasPriorityNegative) {
    return 'ë¶€ì •';
  }
  
  // Enhanced negative keywords
  const negativeKeywords = [
    'ì•ˆë¨', 'ì•ˆë˜ë„¤', 'ëª»í•˜', 'ì•ˆí•´', 'ì‹¤íŒ¨', 'ì—ëŸ¬', 'ì˜¤ë¥˜', 'ë²„ê·¸', 'ë¬¸ì œ', 'ê³ ì¥',
    'ëŠë ¤', 'ëŠë¦¼', 'ë‹µë‹µ', 'ì§œì¦', 'í™”ë‚¨', 'ì‹¤ë§', 'ìµœì•…', 'ë³„ë¡œ', 'êµ¬ë ¤', 'í˜•í¸ì—†',
    'ë‚˜ê°€ë²„ë¦¼', 'êº¼ì ¸', 'ë©ˆì¶¤', 'ë¨¹í†µ', 'ë ‰', 'ëŠê¹€', 'ì•ˆì¢‹', 'ë‚˜ì¨', 'ì‹«ì–´',
    'ê·€ì°®', 'ìŠ¤íŠ¸ë ˆìŠ¤', 'í˜ë“¤', 'ì–´ë µ', 'ë³µì¡', 'ê´‘ê³  ë§', 'ê°•ì œ', 'ëœ¨ê±°ì›€', 'ë°©í•´',
    'ì—†ìŒ', 'ì°¨ë‹¨ ì•ˆ', 'ê³¼ì—´', 'ê±°ìŠ¬ë¦¼'
  ];
  
  // Positive keywords
  const positiveKeywords = [
    'ì¢‹ì•„', 'ì¢‹ë„¤', 'ì¢‹ìŒ', 'í›Œë¥­', 'ìµœê³ ', 'ëŒ€ë°•', 'ì™„ë²½', 'ë©‹ì ¸', 'ì˜ˆì˜', 'ì´ì˜',
    'í¸ë¦¬', 'í¸í•´', 'ì‰¬ì›Œ', 'ê°„ë‹¨', 'ë¹ ë¦„', 'ë¹¨ë¼', 'ë§Œì¡±', 'ì¶”ì²œ', 'ê°ì‚¬', 'ê³ ë§ˆì›Œ',
    'ìœ ìš©', 'ë„ì›€', 'íš¨ê³¼', 'ì„±ê³µ', 'ì˜ë¨', 'ì˜ë˜ë„¤', 'ê´œì°®', 'ë¬´ë‚œ', 'ì ë‹¹'
  ];
  
  // Neutral keywords
  const neutralKeywords = [
    'ê·¸ëƒ¥', 'ë³´í†µ', 'í‰ë²”', 'ì¼ë°˜ì ', 'ê·¸ëŸ­ì €ëŸ­', 'ë‚˜ë¦„', 'ì ì ˆ', 'ë¬´ë‚œ',
    'ì°¸ê³ ', 'ì •ë³´', 'ì•ˆë‚´', 'ì„¤ëª…', 'ì‚¬ìš©ë²•', 'ë°©ë²•', 'ê¸°ëŠ¥', 'ì—…ë°ì´íŠ¸'
  ];
  
  const negativeCount = negativeKeywords.filter(keyword => lowerText.includes(keyword)).length;
  const positiveCount = positiveKeywords.filter(keyword => lowerText.includes(keyword)).length;
  const neutralCount = neutralKeywords.filter(keyword => lowerText.includes(keyword)).length;
  
  // Classification logic
  if (negativeCount >= 2 || (negativeCount > 0 && positiveCount === 0)) {
    return 'ë¶€ì •';
  } else if (positiveCount > negativeCount && neutralCount <= 1) {
    return 'ê¸ì •';
  } else if (neutralCount >= 2 || (neutralCount > 0 && positiveCount === 0 && negativeCount === 0)) {
    return 'ì¤‘ë¦½';
  } else if (positiveCount === negativeCount && positiveCount > 0) {
    return 'ì¤‘ë¦½';
  } else if (positiveCount > 0) {
    return 'ê¸ì •';
  } else {
    return 'ì¤‘ë¦½';
  }
}